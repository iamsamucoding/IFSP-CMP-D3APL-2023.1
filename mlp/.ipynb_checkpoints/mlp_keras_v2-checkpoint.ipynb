{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) with Keras - v2\n",
    "We use the same data from the previous version but we **do not** _flat the data manually_. <br/>\n",
    "Execute all steps ahead and stop at Section 2.\n",
    "\n",
    "In this version we:\n",
    "- Use the _Flatten_ Layer to _flat_ our _input data_\n",
    "- Add regularization to our MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde0def4-7b44-4152-92cd-5fac2922825b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on: <br/>\n",
    "https://machinelearningmastery.com/reproducible-results-neural-networks-keras/ <br/>\n",
    "https://www.tensorflow.org/api_docs/python/tf/random/set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440090b-9df4-425a-944f-6838e2629149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed(42)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3b9b6-207c-4b5a-a243-e68b490c7c1b",
   "metadata": {},
   "source": [
    "#### 1.3 Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9377a2-d2d5-4c3b-825a-f389e6091be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231de637-e2aa-4d28-840a-d8c503f63b75",
   "metadata": {},
   "source": [
    "#### 1.4 Loading Fashion MNIST Dataset via Keras\n",
    "https://keras.io/api/datasets/fashion_mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af01078-3198-47ec-913a-6806fd3910b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a052da-0820-4a38-8456-e0508e61cf65",
   "metadata": {},
   "source": [
    "The dataset is already split into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834d107e-754a-4586-91dd-275e3d8d059c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fashion-mnist', 'mnist.npz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download done in folder: \"~/.keras/datasets\"\n",
    "import os\n",
    "os.listdir(os.path.expanduser('~/.keras/datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aacde3d-5483-468b-9965-d6800199fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1cf3eb2-3952-4bec-bc90-362428e990fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n",
      "Classes: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Classes: {np.unique(y_train).shape[0]}')\n",
    "print(f'Classes: {np.unique(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445f7cbc-6270-4b4e-ae1f-c46408d5d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c4c8ba7-6842-450f-86e2-99c6669f7b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, X_train, y_train):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f'Image: {class_names[label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfb14c2-e805-48e0-b39a-bca995b85dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. value of X_train: 0\n",
      "Max. value of X_train: 255\n",
      "\n",
      "Min. value of X_train: 0\n",
      "Max. value of X_train: 255\n"
     ]
    }
   ],
   "source": [
    "# 8-bit gray scale\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')\n",
    "\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fcb542-031b-4f43-a32e-cc095cc1857b",
   "metadata": {},
   "source": [
    "#### 1.5 (Simple) Feature scaling\n",
    "Since we are going to train the neural network using _Gradient Descent_, we must scale the **input features**. For simplicity, we’ll scale the pixel intensities down to the _0–1_ range by dividing them by **255.0** (8-bit gray image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f955f1b1-3ed9-4dad-a05e-fd8b83e19002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ece1f5-7d6a-4406-bd16-6a6d8017cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. value of X_train: 0.0\n",
      "Max. value of X_train: 1.0\n",
      "\n",
      "Min. value of X_train: 0.0\n",
      "Max. value of X_train: 1.0\n"
     ]
    }
   ],
   "source": [
    "# rescaled 8-bit gray scale\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')\n",
    "\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed90771-4316-4286-89b7-8bbe077db038",
   "metadata": {},
   "source": [
    "## 2. Building and Training a MLP via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f75c8-57b8-4d7f-914b-1369e60cdb19",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture\n",
    "Proposed architecture for Multiclass Classification:\n",
    "- Input Layer: 784 neurons (number of pixels)\n",
    "- Hidden Layer 1: 256 neurons, ReLu, **_He initialization_, L2-regularization**\n",
    "- Hidden Layer 2: 128 neurons, ReLu, **_He initialization_, L2-regularization**\n",
    "- Output Layer: 10 neurons, Softmax, **_Glorot initialization_ (default), L2-regularization**\n",
    "\n",
    "\n",
    "In short: [784], [256 ReLU, 128 ReLU], [10 Softmax] ==> pyramid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9ced7-ea7e-4fac-bd1c-bc82851067a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Defining the Network's Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1dbeb7-b314-4497-84c2-fbe3e7bed327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "X_test.shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01ce1d0b-a7e9-438b-9301-8668a5ac908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff40b8a-dede-4a4e-9918-f45319e03d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=input_shape, name='Input'),\n",
    "    Dense(300, activation='relu', name='Hidden_1',\n",
    "          kernel_initializer='he_normal',\n",
    "          kernel_regularizer=l2(0.01)),  # no penalization/regularization on biases\n",
    "    Dense(100, activation='relu', name='Hidden_2',\n",
    "          kernel_initializer='he_normal',\n",
    "          kernel_regularizer=l2(0.01)),  # no penalization/regularization on biases\n",
    "    Dense(10, activation='softmax', name='Output',\n",
    "          kernel_regularizer=l2(0.01))\n",
    "], name='MyMLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c17a4f68-0316-4aed-adb6-98a7c6ec0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MyMLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (Flatten)             (None, 784)               0         \n",
      "                                                                 \n",
      " Hidden_1 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_2 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85c983-328c-4c21-aaf2-c7feb5bfe523",
   "metadata": {},
   "source": [
    "### 2.2 Compiling: Defining the Loss Function, Optimizer, and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7be8c98-8dc9-4957-ba6c-a81c90801acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1b6ce-3283-46ee-83d1-cce66271eddb",
   "metadata": {},
   "source": [
    "### 2.4 Training\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8580290-0b32-43ac-a33d-735d11c6682a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4761a1f77732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/yeah/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yeah/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dc519-947b-492a-bf99-c6638cf75338",
   "metadata": {},
   "source": [
    "#### **Visualizing the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb091e-a508-4a5b-9efa-6da9d1b47b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69952b3-0c62-48ed-9257-ed851d6b828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a66ed4-74aa-4aa3-9e88-13fb86b5314d",
   "metadata": {},
   "source": [
    "The _training set_ performance ends up beating the _validation performance_, as is generally the case when you train for long enough. <br/>\n",
    "You can tell that the model _has not quite converged yet_, as the _validation loss_ is still (or could be) going down, so you should probably\n",
    "**continue training**.\n",
    "\n",
    "It’s as simple as calling the `fit()` method again, since Keras **_just_ continues training where it left off**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df728186-8b63-491d-a5fd-ca621abb1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d0566-f020-4c21-9f6c-7044816cce36",
   "metadata": {},
   "source": [
    "Note that our _training loss_ is lower than that from the last epoch in the previous training. This confirms that our `fit()` method **continues training** where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9171e0-dd03-4626-8294-6d5083b46782",
   "metadata": {},
   "source": [
    "#### **More about training in Keras**\n",
    "Extracted from \"A. Géron, Hands-on Machine Learning (Chapter 10)\".\n",
    "\n",
    "If the training set was _very skewed_, with some classes being _overrepresented_ and others _underrepresented_, it would be useful to set the `class_weight` argument when calling the `fit()` method, which would give a **larger weight** to _underrepresented classes_ and a **lower weight** to _overrepresented classes_. These weights would be used by Keras when _computing the loss_.\n",
    "\n",
    "If you need _per-instance weights_, set the `sample_weight` argument (if both `class_weight` and `sample_weight` are provided, Keras **multiplies them**).\n",
    "\n",
    "_Per-instance weights_ could be useful if some instances were labeled by _experts_ while others were labeled using a _crowdsourcing platform_: you might want to give more weight to the former."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c5f15-1de7-45d0-8c4f-11db59aea0cf",
   "metadata": {},
   "source": [
    "#### **Saving a Model**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e439e-b0b2-451b-872c-948c31fa0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/mlp_keras_fashionmnist_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d249a00-df74-41b1-b4bb-d764fda7f3e7",
   "metadata": {},
   "source": [
    "See also:\n",
    "- `save_spec`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save_spec\n",
    "- `save_weights`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5fde8-f84f-469d-a5b7-6b879ea24c16",
   "metadata": {},
   "source": [
    "#### **Loading a Model**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#example_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1a710-472a-45bd-842d-845e06c0ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_loaded = load_model('./models/mlp_keras_fashionmnist_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1ae69-28aa-437c-bb94-66b5ea5e2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52717e71-8aa2-4fd1-b25a-e35e73ab9c5a",
   "metadata": {},
   "source": [
    "See also:\n",
    "- `load_weights`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#load_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ca1cb-20b5-439b-8240-e511abb305c7",
   "metadata": {},
   "source": [
    "### 2.5 Evaluating and Predicting New Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db26d3c-46e9-437a-a448-4adf4542958a",
   "metadata": {},
   "source": [
    "#### **Evaluation**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75d26-ca65-405e-85bf-377a035a82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0efd4-0647-435c-a57d-c4d617913992",
   "metadata": {},
   "source": [
    "#### **Prediction**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ea39-55a6-47c9-a5ae-e8d3e41e6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model.predict(X_test)\n",
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d558a-9208-4bb3-bde4-67b1c23bc54c",
   "metadata": {},
   "source": [
    "#### **Class Prediction**\n",
    "https://stackoverflow.com/a/69503180/7069696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_proba, axis=1)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat all steps shown in this notebook for the MNIST dataset available in Keras: <br/>\n",
    "https://keras.io/api/datasets/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99933cce-de11-4828-96b1-efdd7d67b9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
