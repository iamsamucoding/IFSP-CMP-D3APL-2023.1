{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Animal Dataset - v4\n",
    "We will evaluate some **multiclass classification** CNNs to predict the classes of the **Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
    "\n",
    "\n",
    "Target goals:\n",
    "- Custom model:\n",
    "    - VGG16 (with trained weights) for Feature Extraction\n",
    "    - SVM for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a96ce-6d8e-4b7a-b3a6-b442a7865fa3",
   "metadata": {},
   "source": [
    "### 1.2 Allocating memory on demand\n",
    "By default `TensorFlow` allocates _GPU memory_ for the **lifetime of a process**, not the lifetime of the **session object** (so memory can linger much longer than the object). That is why memory is lingering after you stop the program. <br/>\n",
    "Instead, we can indicate to `TensorFlow` allocates **memory on demand**.\n",
    "\n",
    "Sources: <br/>\n",
    "https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
    "\n",
    "https://python.tutorialink.com/cuda-error-out-of-memory-python-process-utilizes-all-gpu-memory/ <br/>\n",
    "https://blog.fearcat.in/a?ID=00950-b4887eea-22e7-4853-b4de-fe746a9e56e6 <br/>\n",
    "https://stackoverflow.com/a/45553529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628add04-bc71-4ffc-91ce-51d49b39e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on:\n",
    "- https://stackoverflow.com/a/59076062\n",
    "- https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41809176-c43b-4143-940e-e63e26394fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    \n",
    "# make some random data\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25efbd0-4d14-4f97-84f7-18e6e103a6b9",
   "metadata": {},
   "source": [
    "### 1.3. Dataset\n",
    "**Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f517d88-8dc2-4339-b788-45fa7f8c5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4511fe-1606-4c2a-afe5-ef9d252cc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "dataset_df_train = pd.read_csv('../datasets/animals-dataset/preprocessed/train.csv')\n",
    "\n",
    "# validation\n",
    "dataset_df_validation = pd.read_csv('../datasets/animals-dataset/preprocessed/validation.csv')\n",
    "\n",
    "# test\n",
    "dataset_df_test = pd.read_csv('../datasets/animals-dataset/preprocessed/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cac26-25c1-467a-a446-4910a9512320",
   "metadata": {},
   "source": [
    "## 2. Building and Training a CNN via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b87c-b0d8-4079-a16d-5dc72ebf5135",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture - VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799b058-6752-4dd0-89c4-7399a5736289",
   "metadata": {},
   "source": [
    "**VGG16 (with pre-trained weights) for feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785d229-156c-4ea0-abd0-aa7030a41c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/applications/vgg/\n",
    "# https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg16 = VGG16(include_top=None,   # we will ignore the top layers that consists of the MLP classifier of VGG16\n",
    "              weights=\"imagenet\", # we will use the weights learned for the ImageNet dataset\n",
    "              input_shape=(100, 100, 3))  # let's consider a smaller resolution than the original paper due to lack of memory\n",
    "\n",
    "# unnecessary because we will not train these network\n",
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816dbb-0592-4971-8fd3-b6f715941d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d658e-f62d-4f6a-9415-8360231978fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2bc705-b54e-438d-b246-f8fe52501c8a",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1e3dd-5b2b-4d8f-92aa-fcfabadbf216",
   "metadata": {},
   "source": [
    "- **Image Resizing**\n",
    "    + Since the **input layer's shape** and the **images' shape** ***are different***, we need to **resize** the images to the **input layer's shape**.\n",
    "    + Let's use the function `c2.resize()` for that: https://learnopencv.com/image-resizing-with-opencv/#resize-by-wdith-height\n",
    "- **Intensity (feature) Scaling**\n",
    "    + Animals dataset contain 24-bit color images, i.e., it is a color image where each channel is a 8-bit grayscale image (values from 0 to 255)\n",
    "    + We will simply rescale the values to [0, 1] by dividing them by 255.\n",
    "- **Label Encoder**\n",
    "    + Encode the string classes into class integers from 0 to n_classes-1\n",
    "    + https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ca34b-6ae9-4aa9-ba30-38e26998ec43",
   "metadata": {},
   "source": [
    "However, the _preprocessing data_ **may not fit into our memory**!!! <br/>\n",
    "So, we need to deal with that first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8901cc1-13cc-462c-9288-9d2d1c6af3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dataset_df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a0c5c-8631-4a97-ad8a-7396b6faf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animals_utils import preprocess_animals_dataset\n",
    "\n",
    "X_train, y_train = preprocess_animals_dataset(dataset_df_train, label_encoder, new_dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5305a-6063-4ea4-8b14-c00df885a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess_animals_dataset(dataset_df_test, label_encoder, new_dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeec23-784d-4071-bd18-6c1bce00aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ff0d1-80a0-4b6a-af93-1708847a8bf2",
   "metadata": {},
   "source": [
    "### 2.3 Feature Extraction by VGG16\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7669827-2fb7-4409-b7ec-c81376ad670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction by VGG16\n",
    "X_train = feat_extractor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddf2a9-e5fa-48fd-a57c-c0fea9d24946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feat_extractor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38410130-5ba0-49a2-844f-67f486dca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763e621-cac7-4ef8-84ea-122391d34f7f",
   "metadata": {},
   "source": [
    "### 2.4 Training a Linear SVM from the extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea73df-c711-4f9a-943c-116d38d3147b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5989ff-30c7-42a3-89de-c5306e61cb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4d444-8282-4dd7-886e-9c5c5641f133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71dc4b9d-d057-4a3d-9b87-142290632c4a",
   "metadata": {},
   "source": [
    "## 3. Evaluating and Predicting New Samples by using our Overfitted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9d666-911d-41e9-9954-f7b844deb99a",
   "metadata": {},
   "source": [
    "#### **Class Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafc6b3-a9c5-4d6f-972f-4796208ca8de",
   "metadata": {},
   "source": [
    "We got the **best accuracy** so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat the experiments considering different classifiers:\n",
    "- Random Forest\n",
    "- RBF SVM\n",
    "- Some other ensemble learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec851d83-1162-409f-875c-4ce31ebb50b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
