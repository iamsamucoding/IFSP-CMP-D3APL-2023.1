{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Animal Dataset - v3\n",
    "We will evaluate some **multiclass classification** CNNs to predict the classes of the **Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
    "\n",
    "\n",
    "Target goals:\n",
    "- Allocating GPU memory on demand\n",
    "- Evaluate VGG16 by transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a96ce-6d8e-4b7a-b3a6-b442a7865fa3",
   "metadata": {},
   "source": [
    "### 1.2 Allocating memory on demand\n",
    "By default `TensorFlow` allocates _GPU memory_ for the **lifetime of a process**, not the lifetime of the **session object** (so memory can linger much longer than the object). That is why memory is lingering after you stop the program. <br/>\n",
    "Instead, we can indicate to `TensorFlow` allocates **memory on demand**.\n",
    "\n",
    "Sources: <br/>\n",
    "https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
    "\n",
    "https://python.tutorialink.com/cuda-error-out-of-memory-python-process-utilizes-all-gpu-memory/ <br/>\n",
    "https://blog.fearcat.in/a?ID=00950-b4887eea-22e7-4853-b4de-fe746a9e56e6 <br/>\n",
    "https://stackoverflow.com/a/45553529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628add04-bc71-4ffc-91ce-51d49b39e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on:\n",
    "- https://stackoverflow.com/a/59076062\n",
    "- https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41809176-c43b-4143-940e-e63e26394fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    \n",
    "# make some random data\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25efbd0-4d14-4f97-84f7-18e6e103a6b9",
   "metadata": {},
   "source": [
    "### 1.3. Dataset\n",
    "**Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f517d88-8dc2-4339-b788-45fa7f8c5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4511fe-1606-4c2a-afe5-ef9d252cc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "dataset_df_train = pd.read_csv('../datasets/animals-dataset/preprocessed/train.csv')\n",
    "\n",
    "# validation\n",
    "dataset_df_validation = pd.read_csv('../datasets/animals-dataset/preprocessed/validation.csv')\n",
    "\n",
    "# test\n",
    "dataset_df_test = pd.read_csv('../datasets/animals-dataset/preprocessed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8398a-523f-4410-acf1-34d68f866b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab0c74-e03e-41f6-b2ce-848fb8b663b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831a4f0-1c20-4cb7-b2b7-d21a98f06f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cac26-25c1-467a-a446-4910a9512320",
   "metadata": {},
   "source": [
    "## 2. Building and Training a CNN via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b87c-b0d8-4079-a16d-5dc72ebf5135",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture - VGG16\n",
    "Original paper: https://arxiv.org/pdf/1409.1556.pdf <br/>\n",
    "Tutorial: https://medium.com/@mygreatlearning/everything-you-need-to-know-about-vgg16-7315defb5918 <br/>\n",
    "Tutorial: https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c\n",
    "\n",
    "\n",
    "<img src='figs/vgg16.png' />\n",
    "\n",
    "<img src='figs/vgg16_architecture.jpeg' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88194f1b-c5d9-40a1-804b-21fa2587c17a",
   "metadata": {},
   "source": [
    "- The 16 in VGG16 refers to 16 layers that have weights. In VGG16 there are thirteen convolutional layers, five Max Pooling layers, and three Dense layers which sum up to 21 layers but it has only sixteen weight layers i.e., learnable parameters layer.\n",
    "- VGG16 takes input tensor size as 224, 244 with 3 RGB channel\n",
    "- Most unique thing about VGG16 is that instead of having a large number of hyper-parameters they focused on having convolution layers of 3x3 filter with stride 1 and always used the same padding and maxpool layer of 2x2 filter of stride 2.\n",
    "- The convolution and max pool layers are consistently arranged throughout the whole architecture\n",
    "- Conv-1 Layer has 64 number of filters, Conv-2 has 128 filters, Conv-3 has 256 filters, Conv 4 and Conv 5 has 512 filters.\n",
    "- Three Fully-Connected (FC) layers follow a stack of convolutional layers: the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63a2a3-8263-4b4a-a610-2664a777b213",
   "metadata": {},
   "source": [
    "We will adapt the original VGG16 architecture for **10 classes** instead of 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0884cc3-1c1a-4e35-9c15-6ee833fecc54",
   "metadata": {},
   "source": [
    "**PS**: Although the _input image dimensions_ is 224x224x3, we will adapt it to **100x100x3** due to **lack of memory** to store our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7c28a-4883-4023-bf36-fb26e42d9784",
   "metadata": {},
   "source": [
    "#### **Transfer Learning**\n",
    "<img src='./figs/transfer_learning.png' />\n",
    "\n",
    "https://www.researchgate.net/figure/The-architecture-of-our-transfer-learning-model_fig4_342400905\n",
    "\n",
    "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799b058-6752-4dd0-89c4-7399a5736289",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Getting the VGG16 with trained weights as our base model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785d229-156c-4ea0-abd0-aa7030a41c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/applications/vgg/\n",
    "# https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# freeze the base model weights ==> these weights won't be updated during training\n",
    "# i.e., the weights of all layers from the base model are not updated\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d658e-f62d-4f6a-9415-8360231978fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2b2da-6f2d-4359-a3dc-fdd41daea358",
   "metadata": {},
   "source": [
    "Note that **there are no Trainable parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522df07-6ad8-4ff0-8a2c-e8ac5825c428",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Plugging a Fully-connected network classifier into the base model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e1728-9b4c-4f6e-be92-c00e8605bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddcafcb-5a90-44bb-af37-70c73c95599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024edf16-0c3b-41b3-8b77-8308d9835105",
   "metadata": {},
   "source": [
    "Although our **model** has _a lot of parameters_, there is a **smaller** number of **trained parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea814b3b-5930-4a61-a57a-e7bd59ba4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bc705-b54e-438d-b246-f8fe52501c8a",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1e3dd-5b2b-4d8f-92aa-fcfabadbf216",
   "metadata": {},
   "source": [
    "- **Image Resizing**\n",
    "    + Since the **input layer's shape** and the **images' shape** ***are different***, we need to **resize** the images to the **input layer's shape**.\n",
    "    + Let's use the function `c2.resize()` for that: https://learnopencv.com/image-resizing-with-opencv/#resize-by-wdith-height\n",
    "- **Intensity (feature) Scaling**\n",
    "    + Animals dataset contain 24-bit color images, i.e., it is a color image where each channel is a 8-bit grayscale image (values from 0 to 255)\n",
    "    + We will simply rescale the values to [0, 1] by dividing them by 255.\n",
    "- **Label Encoder**\n",
    "    + Encode the string classes into class integers from 0 to n_classes-1\n",
    "    + https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ca34b-6ae9-4aa9-ba30-38e26998ec43",
   "metadata": {},
   "source": [
    "However, the _preprocessing data_ **may not fit into our memory**!!! <br/>\n",
    "So, we need to deal with that first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8901cc1-13cc-462c-9288-9d2d1c6af3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dataset_df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a0c5c-8631-4a97-ad8a-7396b6faf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animals_utils import preprocess_animals_dataset\n",
    "\n",
    "X_train, y_train = preprocess_animals_dataset(dataset_df_train, label_encoder, new_dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55311cee-4cc3-49d7-84a2-95980c8a873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocess_animals_dataset(dataset_df_validation, label_encoder, new_dims=(100, 100), verbose=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5305a-6063-4ea4-8b14-c00df885a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess_animals_dataset(dataset_df_test, label_encoder, new_dims=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeec23-784d-4071-bd18-6c1bce00aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_val.shape: {X_val.shape}')\n",
    "print(f'y_val.shape: {y_val.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ff0d1-80a0-4b6a-af93-1708847a8bf2",
   "metadata": {},
   "source": [
    "### 2.3 Training with Early Stopping\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7669827-2fb7-4409-b7ec-c81376ad670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38410130-5ba0-49a2-844f-67f486dca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21232634-024f-4a28-8285-1900da1c6dfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Visualizing the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f323a-bb12-4e64-b10d-2d6c2753484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b7d8c-08eb-4c4b-837f-5830ec5d2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.xticks(range(100))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "history_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "# plt.xticks(range(100))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc4b9d-d057-4a3d-9b87-142290632c4a",
   "metadata": {},
   "source": [
    "## 3. Evaluating and Predicting New Samples by using our Overfitted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114493b-379d-4407-8f3f-278806a9c9fb",
   "metadata": {},
   "source": [
    "#### **Evaluation**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75d26-ca65-405e-85bf-377a035a82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c74cf-ba92-40a3-9bba-728e893a58a8",
   "metadata": {},
   "source": [
    "#### **Prediction**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ea39-55a6-47c9-a5ae-e8d3e41e6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model.predict(X_test)\n",
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9d666-911d-41e9-9954-f7b844deb99a",
   "metadata": {},
   "source": [
    "#### **Class Prediction**\n",
    "https://stackoverflow.com/a/69503180/7069696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_proba, axis=1)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafc6b3-a9c5-4d6f-972f-4796208ca8de",
   "metadata": {},
   "source": [
    "We got the **best accuracy** so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat the experiments considering different networks:\n",
    "- MobileNetV2: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "- VGG19: https://keras.io/api/applications/vgg/\n",
    "- DenseNet: https://keras.io/api/applications/densenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec851d83-1162-409f-875c-4ce31ebb50b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
